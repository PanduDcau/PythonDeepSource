{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-20T20:33:47.480481500Z",
     "start_time": "2023-10-20T20:33:43.971187Z"
    }
   },
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import numpy as np\n",
    "import librosa\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# All emotions on RAVDESS dataset\n",
    "int2emotion = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "# we allow only these emotions\n",
    "AVAILABLE_EMOTIONS = {\n",
    "    \"angry\",\n",
    "    \"sad\",\n",
    "    \"neutral\",\n",
    "    \"happy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def extract_feature(file_name, **kwargs):\n",
    "    \"\"\"\n",
    "    Extract feature from audio file `file_name`\n",
    "        Features supported:\n",
    "            - MFCC (mfcc)\n",
    "            - Chroma (chroma)\n",
    "            - MEL Spectrogram Frequency (mel)\n",
    "            - Contrast (contrast)\n",
    "            - Tonnetz (tonnetz)\n",
    "        e.g:\n",
    "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
    "    \"\"\"\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T20:33:47.507812700Z",
     "start_time": "2023-10-20T20:33:47.480695100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([[-4.56013794e+02,  4.94241371e+01, -2.04614887e+01, ...,\n          1.95963599e-04,  1.31591820e-04,  1.37439391e-04],\n        [-4.22311615e+02,  1.79562702e+01, -1.75061035e+01, ...,\n          6.64979918e-04,  3.57129029e-04,  2.87930830e-04],\n        [-4.02408173e+02,  1.06497669e+01, -1.86298046e+01, ...,\n          5.05983923e-03,  3.38716642e-03,  1.73404091e-03],\n        ...,\n        [-6.21472900e+02,  2.93360786e+01, -1.64034863e+01, ...,\n          1.90901155e-05,  1.05907347e-05,  1.02430777e-05],\n        [-6.76129761e+02,  6.07729759e+01,  8.59902096e+00, ...,\n          1.32644539e-06,  1.24813118e-06,  8.28826273e-07],\n        [-5.95663818e+02,  6.33558578e+01, -9.15794277e+00, ...,\n          6.76750278e-05,  3.17838239e-05,  1.83957854e-05]]),\n array([[-4.84102509e+02,  3.35011826e+01, -4.24036026e+00, ...,\n          3.55753629e-03,  1.79984665e-03,  1.16297312e-03],\n        [-4.35551697e+02,  3.20093689e+01,  5.28842092e-01, ...,\n          1.10966375e-03,  1.26860233e-03,  5.66523755e-04],\n        [-5.25743286e+02,  4.09113770e+01, -2.43286400e+01, ...,\n          4.92031359e-05,  2.16022563e-05,  1.82957665e-05],\n        ...,\n        [-5.86464966e+02,  6.09995308e+01, -4.79248857e+00, ...,\n          1.10175606e-04,  5.12128936e-05,  3.34170509e-05],\n        [-4.14274933e+02,  2.44231701e+01, -8.21840954e+00, ...,\n          4.73834854e-03,  2.84270849e-03,  2.24995054e-03],\n        [-6.34137024e+02,  5.98251724e+01,  6.51384211e+00, ...,\n          9.31881732e-06,  3.36647190e-06,  2.70885130e-06]]),\n ['angry',\n  'angry',\n  'angry',\n  'angry',\n  'angry',\n  'neutral',\n  'angry',\n  'sad',\n  'happy',\n  'happy',\n  'happy',\n  'angry',\n  'sad',\n  'angry',\n  'happy',\n  'angry',\n  'sad',\n  'angry',\n  'happy',\n  'angry',\n  'neutral',\n  'happy',\n  'happy',\n  'neutral',\n  'angry',\n  'happy',\n  'neutral',\n  'happy',\n  'angry',\n  'happy',\n  'angry',\n  'sad',\n  'angry',\n  'sad',\n  'sad',\n  'sad',\n  'neutral',\n  'sad',\n  'neutral',\n  'sad',\n  'neutral',\n  'angry',\n  'happy',\n  'angry',\n  'sad',\n  'neutral',\n  'angry',\n  'angry',\n  'angry',\n  'angry',\n  'angry',\n  'sad',\n  'neutral',\n  'happy',\n  'sad',\n  'sad',\n  'sad',\n  'angry',\n  'sad',\n  'happy',\n  'angry',\n  'angry',\n  'neutral',\n  'happy',\n  'happy',\n  'angry',\n  'angry',\n  'happy',\n  'angry',\n  'happy',\n  'happy',\n  'happy',\n  'sad',\n  'sad',\n  'happy',\n  'happy',\n  'happy',\n  'happy',\n  'angry',\n  'happy',\n  'happy',\n  'angry',\n  'angry',\n  'sad',\n  'happy',\n  'happy',\n  'happy',\n  'angry',\n  'happy',\n  'sad',\n  'happy',\n  'happy',\n  'sad',\n  'happy',\n  'sad',\n  'happy',\n  'sad',\n  'sad',\n  'angry',\n  'angry',\n  'happy',\n  'sad',\n  'sad',\n  'angry',\n  'sad',\n  'angry',\n  'neutral',\n  'happy',\n  'happy',\n  'sad',\n  'angry',\n  'angry',\n  'sad',\n  'neutral',\n  'angry',\n  'happy',\n  'angry',\n  'neutral',\n  'sad',\n  'sad',\n  'happy',\n  'happy',\n  'happy',\n  'angry',\n  'angry',\n  'neutral',\n  'happy',\n  'sad',\n  'sad',\n  'neutral',\n  'sad',\n  'happy',\n  'happy',\n  'happy',\n  'happy',\n  'neutral',\n  'sad',\n  'angry',\n  'happy',\n  'sad',\n  'angry',\n  'neutral',\n  'sad',\n  'happy',\n  'happy',\n  'happy',\n  'neutral',\n  'happy',\n  'angry',\n  'neutral',\n  'happy',\n  'neutral',\n  'sad',\n  'happy',\n  'happy',\n  'angry',\n  'neutral',\n  'angry',\n  'neutral',\n  'happy',\n  'sad',\n  'neutral',\n  'angry',\n  'neutral',\n  'angry',\n  'happy',\n  'angry',\n  'neutral',\n  'neutral',\n  'angry',\n  'happy',\n  'sad',\n  'happy',\n  'neutral',\n  'angry',\n  'sad',\n  'neutral',\n  'sad',\n  'angry',\n  'neutral',\n  'sad',\n  'sad',\n  'happy',\n  'angry',\n  'happy',\n  'neutral',\n  'happy',\n  'happy',\n  'neutral',\n  'happy',\n  'sad',\n  'happy',\n  'neutral',\n  'happy',\n  'happy',\n  'angry',\n  'angry',\n  'angry',\n  'sad',\n  'sad',\n  'angry',\n  'happy',\n  'sad',\n  'sad',\n  'sad',\n  'neutral',\n  'angry',\n  'sad',\n  'sad',\n  'sad',\n  'neutral',\n  'happy',\n  'neutral',\n  'neutral',\n  'sad',\n  'sad',\n  'angry',\n  'angry',\n  'happy',\n  'sad',\n  'sad',\n  'neutral',\n  'neutral',\n  'angry',\n  'angry',\n  'angry',\n  'angry',\n  'happy',\n  'happy',\n  'neutral',\n  'neutral',\n  'neutral',\n  'sad',\n  'neutral',\n  'angry',\n  'angry',\n  'sad',\n  'sad',\n  'sad',\n  'happy',\n  'sad',\n  'neutral',\n  'sad',\n  'happy',\n  'sad',\n  'angry',\n  'angry',\n  'happy',\n  'angry',\n  'happy',\n  'happy',\n  'happy',\n  'happy',\n  'sad',\n  'angry',\n  'sad',\n  'happy',\n  'angry',\n  'sad',\n  'angry',\n  'sad',\n  'happy',\n  'happy',\n  'happy',\n  'happy',\n  'happy',\n  'sad',\n  'sad',\n  'neutral',\n  'angry',\n  'angry',\n  'sad',\n  'sad',\n  'angry',\n  'happy',\n  'sad',\n  'angry',\n  'sad',\n  'sad',\n  'happy',\n  'happy',\n  'happy',\n  'angry',\n  'sad',\n  'happy',\n  'neutral',\n  'angry',\n  'neutral',\n  'sad',\n  'happy',\n  'sad',\n  'sad',\n  'sad',\n  'happy',\n  'sad',\n  'happy',\n  'sad',\n  'happy',\n  'sad',\n  'sad',\n  'sad',\n  'happy',\n  'happy',\n  'happy',\n  'sad',\n  'happy',\n  'neutral',\n  'angry',\n  'sad',\n  'happy',\n  'angry',\n  'sad',\n  'angry',\n  'neutral',\n  'happy',\n  'happy',\n  'angry',\n  'angry',\n  'angry',\n  'neutral',\n  'happy',\n  'happy',\n  'angry',\n  'angry',\n  'angry',\n  'angry',\n  'angry',\n  'sad',\n  'sad',\n  'angry',\n  'sad',\n  'happy',\n  'happy',\n  'neutral',\n  'angry',\n  'angry',\n  'angry',\n  'sad',\n  'happy',\n  'neutral',\n  'happy',\n  'angry',\n  'angry',\n  'sad',\n  'happy',\n  'sad',\n  'angry',\n  'angry',\n  'happy',\n  'happy',\n  'sad',\n  'neutral',\n  'happy',\n  'sad',\n  'angry',\n  'happy',\n  'angry',\n  'angry',\n  'happy',\n  'sad',\n  'happy',\n  'happy',\n  'sad',\n  'happy',\n  'sad',\n  'sad',\n  'neutral',\n  'sad',\n  'happy',\n  'angry',\n  'sad',\n  'neutral',\n  'sad',\n  'neutral',\n  'happy',\n  'angry',\n  'sad',\n  'angry',\n  'happy',\n  'sad',\n  'neutral',\n  'sad',\n  'sad',\n  'sad',\n  'neutral',\n  'neutral',\n  'happy',\n  'angry',\n  'sad',\n  'happy',\n  'neutral',\n  'happy',\n  'sad',\n  'sad',\n  'happy',\n  'sad',\n  'happy',\n  'angry',\n  'sad',\n  'angry',\n  'sad',\n  'sad',\n  'sad',\n  'angry',\n  'happy',\n  'happy',\n  'sad',\n  'happy',\n  'happy',\n  'sad',\n  'angry',\n  'neutral',\n  'angry',\n  'neutral',\n  'neutral',\n  'angry',\n  'neutral',\n  'angry',\n  'happy',\n  'angry',\n  'happy',\n  'neutral',\n  'sad',\n  'angry',\n  'sad',\n  'angry',\n  'happy',\n  'angry',\n  'happy',\n  'happy',\n  'happy',\n  'angry',\n  'angry',\n  'angry',\n  'sad',\n  'sad',\n  'angry',\n  'neutral',\n  'neutral',\n  'neutral',\n  'sad',\n  'sad',\n  'neutral',\n  'sad',\n  'neutral',\n  'happy',\n  'neutral',\n  'sad',\n  'angry',\n  'sad',\n  'happy',\n  'sad',\n  'sad',\n  'angry',\n  'happy',\n  'angry',\n  'happy',\n  'happy',\n  'happy',\n  'neutral',\n  'angry',\n  'neutral',\n  'angry',\n  'sad',\n  'angry',\n  'sad',\n  'happy',\n  'angry',\n  'angry',\n  'happy',\n  'angry',\n  'sad',\n  'angry',\n  'happy',\n  'happy',\n  'happy',\n  'sad',\n  'sad',\n  'neutral',\n  'angry',\n  'angry',\n  'happy',\n  'angry',\n  'neutral',\n  'happy',\n  'happy',\n  'happy',\n  'happy',\n  'neutral',\n  'sad',\n  'angry',\n  'angry',\n  'sad',\n  'sad',\n  'happy',\n  'happy',\n  'happy',\n  'sad',\n  'angry',\n  'happy',\n  'angry',\n  'sad',\n  'sad',\n  'sad',\n  'happy',\n  'happy',\n  'happy',\n  'angry',\n  'neutral',\n  'sad',\n  'sad',\n  'sad',\n  'sad',\n  'angry',\n  'happy',\n  'angry',\n  'sad',\n  'happy',\n  'angry',\n  'sad',\n  'sad',\n  'angry',\n  'angry',\n  'neutral',\n  'happy',\n  'angry',\n  'neutral',\n  'happy',\n  'sad',\n  'sad',\n  'angry',\n  'sad',\n  'sad',\n  'angry',\n  'happy',\n  'neutral',\n  'happy'],\n ['happy',\n  'angry',\n  'happy',\n  'sad',\n  'angry',\n  'angry',\n  'happy',\n  'angry',\n  'angry',\n  'happy',\n  'sad',\n  'neutral',\n  'neutral',\n  'neutral',\n  'sad',\n  'neutral',\n  'happy',\n  'angry',\n  'sad',\n  'sad',\n  'happy',\n  'sad',\n  'neutral',\n  'happy',\n  'neutral',\n  'happy',\n  'angry',\n  'angry',\n  'neutral',\n  'angry',\n  'sad',\n  'happy',\n  'happy',\n  'angry',\n  'neutral',\n  'sad',\n  'sad',\n  'sad',\n  'angry',\n  'sad',\n  'sad',\n  'angry',\n  'angry',\n  'sad',\n  'neutral',\n  'sad',\n  'happy',\n  'neutral',\n  'neutral',\n  'sad',\n  'sad',\n  'sad',\n  'happy',\n  'happy',\n  'sad',\n  'angry',\n  'angry',\n  'happy',\n  'happy',\n  'angry',\n  'neutral',\n  'happy',\n  'sad',\n  'sad',\n  'angry',\n  'neutral',\n  'neutral',\n  'angry',\n  'happy',\n  'angry',\n  'happy',\n  'happy',\n  'sad',\n  'angry',\n  'angry',\n  'angry',\n  'angry',\n  'happy',\n  'sad',\n  'angry',\n  'sad',\n  'sad',\n  'happy',\n  'angry',\n  'sad',\n  'happy',\n  'sad',\n  'sad',\n  'sad',\n  'angry',\n  'sad',\n  'sad',\n  'sad',\n  'angry',\n  'happy',\n  'angry',\n  'angry',\n  'sad',\n  'sad',\n  'happy',\n  'neutral',\n  'sad',\n  'angry',\n  'happy',\n  'sad',\n  'angry',\n  'angry',\n  'angry',\n  'angry',\n  'sad',\n  'angry',\n  'sad',\n  'angry',\n  'happy',\n  'angry',\n  'sad',\n  'angry',\n  'angry',\n  'happy',\n  'happy',\n  'sad',\n  'happy',\n  'happy',\n  'angry',\n  'neutral',\n  'neutral',\n  'angry',\n  'sad',\n  'angry',\n  'angry',\n  'angry',\n  'angry',\n  'sad',\n  'angry',\n  'happy']]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def load_data(test_size=0.2):\n",
    "test_size=0.2\n",
    "X, y = [], []\n",
    "for file in glob.glob(\"data/Actor_*/*.wav\"):\n",
    "    # get the base name of the audio file\n",
    "    basename = os.path.basename(file)\n",
    "    # get the emotion label\n",
    "    emotion = int2emotion[basename.split(\"-\")[2]]\n",
    "    # we allow only AVAILABLE_EMOTIONS we set\n",
    "    if emotion not in AVAILABLE_EMOTIONS:\n",
    "        continue\n",
    "    # extract speech features\n",
    "    features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "    # add to data\n",
    "    X.append(features)\n",
    "    y.append(emotion)\n",
    "# split the data to training and testing and return it\n",
    "train_test_split(np.array(X), y, test_size=test_size, random_state=7)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T20:34:04.487491300Z",
     "start_time": "2023-10-20T20:33:47.495484Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def load_data(test_size=0.25):\n",
    "    test_size=0.2\n",
    "    X, y = [], []\n",
    "    for file in glob.glob(\"data/Actor_*/*.wav\"):\n",
    "        # get the base name of the audio file\n",
    "        basename = os.path.basename(file)\n",
    "        # get the emotion label\n",
    "        emotion = int2emotion[basename.split(\"-\")[2]]\n",
    "        # we allow only AVAILABLE_EMOTIONS we set\n",
    "        if emotion not in AVAILABLE_EMOTIONS:\n",
    "            continue\n",
    "        # extract speech features\n",
    "        features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        # add to data\n",
    "        X.append(features)\n",
    "        y.append(emotion)\n",
    "    # split the data to training and testing and return it\n",
    "    return train_test_split(np.array(X), y, test_size=test_size, random_state=7)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T20:34:04.532721300Z",
     "start_time": "2023-10-20T20:34:04.490607700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from utils import load_data\n",
    "\n",
    "import os\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T20:34:04.536694500Z",
     "start_time": "2023-10-20T20:34:04.505621800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Number of training samples: 470\n",
      "[+] Number of testing samples: 202\n",
      "[+] Number of features: 180\n",
      "[*] Training the model...\n",
      "Accuracy: 76.73%\n"
     ]
    }
   ],
   "source": [
    "# load RAVDESS dataset\n",
    "X_train, X_test, y_train, y_test = load_data(test_size=0.30)\n",
    "\n",
    "# print some details\n",
    "# number of samples in training data\n",
    "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
    "# number of samples in testing data\n",
    "print(\"[+] Number of testing samples:\", X_test.shape[0])\n",
    "\n",
    "# number of features used\n",
    "# this is a vector of features extracted\n",
    "# using utils.extract_features() method\n",
    "print(\"[+] Number of features:\", X_train.shape[1])\n",
    "# best model, determined by a grid search\n",
    "model_params = {\n",
    "    'alpha': 0.01,\n",
    "    'batch_size': 256,\n",
    "    'epsilon': 1e-08,\n",
    "    'hidden_layer_sizes': (300,),\n",
    "    'learning_rate': 'adaptive',\n",
    "    'max_iter': 500,\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize Multi Layer Perceptron classifier with Best Parameters\n",
    "model = MLPClassifier(**model_params)\n",
    "\n",
    "# train the model\n",
    "print(\"[*] Training the model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict 25% of data to measure how good we are\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
    "\n",
    "# now we save the model\n",
    "# make result directory if doesn't exist yet\n",
    "if not os.path.isdir(\"result\"):\n",
    "    os.mkdir(\"result\")\n",
    "\n",
    "pickle.dump(model, open(\"result/mlp_classifier2.model\", \"wb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T20:34:15.106017200Z",
     "start_time": "2023-10-20T20:34:04.532721300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07\n",
      "disgust\n"
     ]
    }
   ],
   "source": [
    "baseline = \"03-01-07-02-02-01-18.wav\"\n",
    "em=baseline.split(\"-\")[2]\n",
    "emotion = int2emotion[baseline.split(\"-\")[2]]\n",
    "\n",
    "print(em)\n",
    "print(emotion)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T20:34:21.928194200Z",
     "start_time": "2023-10-20T20:34:21.919220100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "RATE = 16000\n",
    "from scipy.io import wavfile\n",
    "import noisereduce as nr\n",
    "# load data\n",
    "rate, data = wavfile.read(\"result/test.wav\")\n",
    "# perform noise reduction\n",
    "reduced_noise = nr.reduce_noise(y=data, sr=RATE)\n",
    "wavfile.write(\"result/myred_noise.wav\", rate, reduced_noise)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T09:17:32.044578800Z",
     "start_time": "2023-10-19T09:17:31.925377500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
