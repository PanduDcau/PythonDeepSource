{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_a_Spark_NLP_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Zv_JPHsqyvFI"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "yU4V9RT-yvFN"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/models_hub/Train_a_Spark_NLP_Model.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "uRIWOVT-yvFO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZEkgBuabyGF"
      },
      "source": [
        "%%capture\n",
        " \n",
        "# Setup Spark NLP on Colab\n",
        "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/colab_setup.sh -O - | bash"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i4Z9OrgcE4b",
        "outputId": "e6e0f237-ff86-4453-ce5d-7dec18ccf669"
      },
      "source": [
        "import sparknlp\n",
        " \n",
        "spark = sparknlp.start() # for GPU training >> sparknlp.start(gpu = True) # for Spark 2.3 =>> sparknlp.start(spark23 = True)\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        " \n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        " \n",
        "print(\"Apache Spark version:\", spark.version)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version 3.1.0\n",
            "Apache Spark version: 3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooWKiaQEcUPB"
      },
      "source": [
        "#download training data\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/conll2003/eng.train\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/conll2003/eng.testa"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn72rDuTcW_l"
      },
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "training_data = CoNLL().readDataset(spark, './eng.train')\n",
        "testing_data= CoNLL().readDataset(spark, './eng.testa')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RW2pBP_cdgP",
        "outputId": "2e9359f7-1557-4cba-cf54-a7d66d5d6cd2"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "training_data.select(F.explode(F.arrays_zip('token.result', 'pos.result',  'label.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "        F.expr(\"cols['1']\").alias(\"pos\"),\n",
        "        F.expr(\"cols['2']\").alias(\"ner_label\")).show(truncate=50)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+---------+\n",
            "|     token|pos|ner_label|\n",
            "+----------+---+---------+\n",
            "|        EU|NNP|    B-ORG|\n",
            "|   rejects|VBZ|        O|\n",
            "|    German| JJ|   B-MISC|\n",
            "|      call| NN|        O|\n",
            "|        to| TO|        O|\n",
            "|   boycott| VB|        O|\n",
            "|   British| JJ|   B-MISC|\n",
            "|      lamb| NN|        O|\n",
            "|         .|  .|        O|\n",
            "|     Peter|NNP|    B-PER|\n",
            "| Blackburn|NNP|    I-PER|\n",
            "|  BRUSSELS|NNP|    B-LOC|\n",
            "|1996-08-22| CD|        O|\n",
            "|       The| DT|        O|\n",
            "|  European|NNP|    B-ORG|\n",
            "|Commission|NNP|    I-ORG|\n",
            "|      said|VBD|        O|\n",
            "|        on| IN|        O|\n",
            "|  Thursday|NNP|        O|\n",
            "|        it|PRP|        O|\n",
            "+----------+---+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLule_H4rDmv"
      },
      "source": [
        "## 1. Create Spark NLP train pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6mvq8Avcjyx"
      },
      "source": [
        "!mkdir ner_logs"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zijeZRPrcmE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4248adc-5cf6-40c0-a61b-dca61d7a8844"
      },
      "source": [
        "# You can use any word embeddings you want (Glove, Elmo, Bert, custom etc.)\n",
        "\n",
        "embeddings = WordEmbeddingsModel.pretrained('glove_100d')\\\n",
        "          .setInputCols([\"document\", \"token\"])\\\n",
        "          .setOutputCol(\"embeddings\")\n",
        "\n",
        "nerTagger = NerDLApproach()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "      .setLabelColumn(\"label\")\\\n",
        "      .setOutputCol(\"ner\")\\\n",
        "      .setMaxEpochs(1)\\\n",
        "      .setLr(0.003)\\\n",
        "      .setBatchSize(32)\\\n",
        "      .setRandomSeed(0)\\\n",
        "      .setVerbose(1)\\\n",
        "      .setValidationSplit(0.2)\\\n",
        "      .setEvaluationLogExtended(True) \\\n",
        "      .setEnableOutputLogs(True)\\\n",
        "      .setIncludeConfidence(True)\\\n",
        "      .setOutputLogsPath('ner_logs') # if not set, logs will be written to ~/annotator_logs\n",
        " #    .setGraphFolder('graphs') >> put your graph file (pb) under this folder if you are using a custom graph generated thru 4.1 NerDL-Graph.ipynb notebook\n",
        " #    .setEnableMemoryOptimizer() >> if you have a limited memory and a large conll file, you can set this True to train batch by batch \n",
        "    \n",
        "ner_converter = NerConverter() \\\n",
        "    .setInputCols(['document', 'token', 'ner']) \\\n",
        "    .setOutputCol('ner_chunk')\n",
        "\n",
        "ner_pipeline = Pipeline(stages=[\n",
        "      embeddings,\n",
        "      nerTagger,\n",
        "      ner_converter\n",
        " ])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lJ8fCjmrLtw"
      },
      "source": [
        "## 2. Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsJO74W-czVS",
        "outputId": "9abfea0e-1977-4a74-b313-628e9a3ca045"
      },
      "source": [
        "%%time\n",
        "ner_model = ner_pipeline.fit(training_data)\n",
        "ner_model.stages[-1].write().overwrite().save('outputs/ner_wiki_glove100d_en')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.17 s, sys: 123 ms, total: 1.3 s\n",
            "Wall time: 3min 28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TIDdUYHdG7y",
        "outputId": "f9903e54-8f45-44e1-f215-46f2187c0ae2"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "predictions = ner_model.transform(testing_data) \n",
        "predictions.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
        "           .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "                   F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
        "                   F.expr(\"cols['2']\").alias(\"prediction\")).show(truncate=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+----------+\n",
            "|token         |ground_truth|prediction|\n",
            "+--------------+------------+----------+\n",
            "|CRICKET       |O           |O         |\n",
            "|-             |O           |O         |\n",
            "|LEICESTERSHIRE|B-ORG       |B-ORG     |\n",
            "|TAKE          |O           |O         |\n",
            "|OVER          |O           |O         |\n",
            "|AT            |O           |O         |\n",
            "|TOP           |O           |O         |\n",
            "|AFTER         |O           |O         |\n",
            "|INNINGS       |O           |O         |\n",
            "|VICTORY       |O           |O         |\n",
            "|.             |O           |O         |\n",
            "|LONDON        |B-LOC       |B-LOC     |\n",
            "|1996-08-30    |O           |O         |\n",
            "|West          |B-MISC      |B-MISC    |\n",
            "|Indian        |I-MISC      |I-MISC    |\n",
            "|all-rounder   |O           |O         |\n",
            "|Phil          |B-PER       |B-PER     |\n",
            "|Simmons       |I-PER       |I-PER     |\n",
            "|took          |O           |O         |\n",
            "|four          |O           |O         |\n",
            "+--------------+------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7gTMzBXSJY1"
      },
      "source": [
        "## 3. Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV8fcONKdMgF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d54b5661-78e5-4589-ec5b-04d03b753f34"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        " \n",
        "preds_df = predictions.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
        "                      .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "                              F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
        "                              F.expr(\"cols['2']\").alias(\"prediction\")).toPandas()\n",
        " \n",
        "print(classification_report(preds_df['ground_truth'], preds_df['prediction']))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.90      0.95      0.92      1837\n",
            "      B-MISC       0.86      0.86      0.86       922\n",
            "       B-ORG       0.92      0.78      0.84      1341\n",
            "       B-PER       0.91      0.97      0.94      1842\n",
            "       I-LOC       0.77      0.82      0.79       257\n",
            "      I-MISC       0.75      0.63      0.68       346\n",
            "       I-ORG       0.89      0.62      0.73       751\n",
            "       I-PER       0.96      0.97      0.96      1307\n",
            "           O       0.99      1.00      0.99     42759\n",
            "\n",
            "    accuracy                           0.98     51362\n",
            "   macro avg       0.88      0.84      0.86     51362\n",
            "weighted avg       0.98      0.98      0.98     51362\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "562zPiw4SlRg"
      },
      "source": [
        "## 4. Saving model and Zipping it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwIo061j8KPm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cdb5b53e-c3e7-40ab-aa9f-3d970a7ab28d"
      },
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"/content/outputs/ner_wiki_glove100d_en\", 'zip', \"/content/outputs/ner_wiki_glove100d_en\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/outputs/ner_wiki_glove100d_en.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}