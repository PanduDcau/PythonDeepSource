{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "172e391e",
   "metadata": {},
   "source": [
    "## Labsheet 3 - 18001149"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07370f86",
   "metadata": {},
   "source": [
    "### Counting words and n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b7d2d04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg #Importing Nltk text files\n",
    "from nltk import FreqDist\n",
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981ffac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Punctuation work\n",
    "import nltk\n",
    "file0 = gutenberg.fileids()[0]\n",
    "emmatext = gutenberg.raw(file0)\n",
    "emmatokens = nltk.wordpunct_tokenize(emmatext)\n",
    "emmawords = [w.lower() for w in emmatokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ef2578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'woodhouse',\n",
       " ',',\n",
       " 'handsome',\n",
       " ',',\n",
       " 'clever',\n",
       " ',',\n",
       " 'and',\n",
       " 'rich',\n",
       " ',',\n",
       " 'with',\n",
       " 'a',\n",
       " 'comfortable',\n",
       " 'home',\n",
       " 'and',\n",
       " 'happy',\n",
       " 'disposition',\n",
       " ',',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'unite',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'best',\n",
       " 'blessings',\n",
       " 'of',\n",
       " 'existence',\n",
       " ';',\n",
       " 'and',\n",
       " 'had',\n",
       " 'lived',\n",
       " 'nearly',\n",
       " 'twenty',\n",
       " '-',\n",
       " 'one',\n",
       " 'years',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'with',\n",
       " 'very',\n",
       " 'little',\n",
       " 'to',\n",
       " 'distress',\n",
       " 'or',\n",
       " 'vex',\n",
       " 'her',\n",
       " '.',\n",
       " 'she',\n",
       " 'was',\n",
       " 'the',\n",
       " 'youngest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'two',\n",
       " 'daughters',\n",
       " 'of',\n",
       " 'a',\n",
       " 'most',\n",
       " 'affectionate',\n",
       " ',',\n",
       " 'indulgent',\n",
       " 'father',\n",
       " ';',\n",
       " 'and',\n",
       " 'had',\n",
       " ',',\n",
       " 'in',\n",
       " 'consequence',\n",
       " 'of',\n",
       " 'her',\n",
       " 'sister',\n",
       " \"'\",\n",
       " 's',\n",
       " 'marriage',\n",
       " ',',\n",
       " 'been',\n",
       " 'mistress',\n",
       " 'of',\n",
       " 'his',\n",
       " 'house',\n",
       " 'from',\n",
       " 'a',\n",
       " 'very',\n",
       " 'early',\n",
       " 'period',\n",
       " '.',\n",
       " 'her',\n",
       " 'mother',\n",
       " 'had',\n",
       " 'died',\n",
       " 'too',\n",
       " 'long',\n",
       " 'ago',\n",
       " 'for',\n",
       " 'her',\n",
       " 'to',\n",
       " 'have',\n",
       " 'more']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing Stopwords\n",
    "shortwords = emmawords[11:111]\n",
    "shortwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24962d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['emma', 'woodhouse', ',', 'handsome', 'clever', 'and', 'rich', 'with', 'a', 'comfortable', 'home', 'happy', 'disposition', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'existence', ';', 'had', 'lived', 'nearly', 'twenty', '-', 'one', 'years', 'in', 'world', 'very', 'little', 'distress', 'or', 'vex', 'her', '.', 'she', 'was', 'youngest', 'two', 'daughters', 'most', 'affectionate', 'indulgent', 'father', 'consequence', 'sister', \"'\", 's', 'marriage', 'been', 'mistress', 'his', 'house', 'from', 'early', 'period', 'mother', 'died', 'too', 'long', 'ago', 'for', 'have', 'more'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing Shortwords with relevent Keys\n",
    "shortdist = FreqDist(shortwords)\n",
    "shortdist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57ad698c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma 1\n",
      "woodhouse 1\n",
      ", 8\n",
      "handsome 1\n",
      "clever 1\n",
      "and 4\n",
      "rich 1\n",
      "with 2\n",
      "a 3\n",
      "comfortable 1\n",
      "home 1\n",
      "happy 1\n",
      "disposition 1\n",
      "seemed 1\n",
      "to 3\n",
      "unite 1\n",
      "some 1\n",
      "of 6\n",
      "the 4\n",
      "best 1\n",
      "blessings 1\n",
      "existence 1\n",
      "; 2\n",
      "had 3\n",
      "lived 1\n",
      "nearly 1\n",
      "twenty 1\n",
      "- 1\n",
      "one 1\n",
      "years 1\n",
      "in 2\n",
      "world 1\n",
      "very 2\n",
      "little 1\n",
      "distress 1\n",
      "or 1\n",
      "vex 1\n",
      "her 4\n",
      ". 2\n",
      "she 1\n",
      "was 1\n",
      "youngest 1\n",
      "two 1\n",
      "daughters 1\n",
      "most 1\n",
      "affectionate 1\n",
      "indulgent 1\n",
      "father 1\n",
      "consequence 1\n",
      "sister 1\n",
      "' 1\n",
      "s 1\n",
      "marriage 1\n",
      "been 1\n",
      "mistress 1\n",
      "his 1\n",
      "house 1\n",
      "from 1\n",
      "early 1\n",
      "period 1\n",
      "mother 1\n",
      "died 1\n",
      "too 1\n",
      "long 1\n",
      "ago 1\n",
      "for 1\n",
      "have 1\n",
      "more 1\n"
     ]
    }
   ],
   "source": [
    "#Getting frequency distribution\n",
    "for word in shortdist.keys():\n",
    "    print(word,shortdist[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcf755f",
   "metadata": {},
   "source": [
    "### More Specialized Frequency Distributions in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b8923f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched non-alphabetical\n"
     ]
    }
   ],
   "source": [
    "#Regex analyzation\n",
    "import re\n",
    "pattern = re.compile('.*[^a-z].*')\n",
    "nonAlphaMatch = pattern.match('-')\n",
    "if nonAlphaMatch: \n",
    "    print('matched non-alphabetical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeae02b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop!\n"
     ]
    }
   ],
   "source": [
    "#testing Stopwords\n",
    "stopwords = ['to', 'be', 'of', 'the', 'in', 'it', 'was',\n",
    "'i', 'am', 'she', 'had', 'been', 'is', 'have','could', 'not',\n",
    "'her', 'he', 'do', 'and', 'would', 'such', 'a', 'his', 'must']\n",
    "word = 'the'\n",
    "if word in stopwords:\n",
    "    print('Stop!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91509704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphaStopFreqDist(words, stoplist):\n",
    "# make a new frequency distribution called asdist\n",
    "  asdist = FreqDist()\n",
    "# define the regular expression pattern to match\n",
    "# non-alphabetical tokens\n",
    "  pattern = re.compile('.*[^a-z].*')\n",
    "# for every token, if it doesn't match the non-alphabetical\n",
    "# pattern and if it is not on the stop word list add it to\n",
    "# the frequency distribution\n",
    "  for word in words:\n",
    "    if not pattern.match(word):\n",
    "        if not word in stoplist:\n",
    "            asdist[word] += 1\n",
    "# return the frequency distribution as the result\n",
    "  return asdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "317b0bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'woodhouse',\n",
       " 'handsome',\n",
       " 'clever',\n",
       " 'rich',\n",
       " 'with',\n",
       " 'comfortable',\n",
       " 'home',\n",
       " 'happy',\n",
       " 'disposition',\n",
       " 'seemed',\n",
       " 'unite',\n",
       " 'some',\n",
       " 'best',\n",
       " 'blessings',\n",
       " 'existence',\n",
       " 'lived',\n",
       " 'nearly',\n",
       " 'twenty',\n",
       " 'one',\n",
       " 'years',\n",
       " 'world',\n",
       " 'very',\n",
       " 'little',\n",
       " 'distress',\n",
       " 'or',\n",
       " 'vex',\n",
       " 'youngest',\n",
       " 'two',\n",
       " 'daughters',\n",
       " 'most',\n",
       " 'affectionate',\n",
       " 'indulgent',\n",
       " 'father',\n",
       " 'consequence',\n",
       " 'sister',\n",
       " 's',\n",
       " 'marriage',\n",
       " 'mistress',\n",
       " 'house',\n",
       " 'from',\n",
       " 'early',\n",
       " 'period',\n",
       " 'mother',\n",
       " 'died',\n",
       " 'too',\n",
       " 'long',\n",
       " 'ago',\n",
       " 'for',\n",
       " 'more']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Listing keys of the filtered words\n",
    "asdist = alphaStopFreqDist(shortwords, stopwords)\n",
    "list(asdist.keys())[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7928ecda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma 1\n",
      "woodhouse 1\n",
      "handsome 1\n",
      "clever 1\n",
      "rich 1\n",
      "with 2\n",
      "comfortable 1\n",
      "home 1\n",
      "happy 1\n",
      "disposition 1\n",
      "seemed 1\n",
      "unite 1\n",
      "some 1\n",
      "best 1\n",
      "blessings 1\n",
      "existence 1\n",
      "lived 1\n",
      "nearly 1\n",
      "twenty 1\n",
      "one 1\n",
      "years 1\n",
      "world 1\n",
      "very 2\n",
      "little 1\n",
      "distress 1\n",
      "or 1\n",
      "vex 1\n",
      "youngest 1\n",
      "two 1\n",
      "daughters 1\n"
     ]
    }
   ],
   "source": [
    "#frequency distribution\n",
    "for key in list(asdist.keys())[:30]:\n",
    "    print(key, asdist[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e5ebeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma 865\n",
      "by 571\n",
      "jane 301\n",
      "austen 1\n",
      "volume 3\n",
      "chapter 56\n",
      "woodhouse 313\n",
      "handsome 38\n",
      "clever 27\n",
      "rich 14\n",
      "with 1217\n",
      "comfortable 34\n",
      "home 130\n",
      "happy 125\n",
      "disposition 24\n",
      "seemed 141\n",
      "unite 3\n",
      "some 262\n",
      "best 85\n",
      "blessings 6\n",
      "existence 8\n",
      "lived 25\n",
      "nearly 14\n",
      "twenty 30\n",
      "one 452\n",
      "years 57\n",
      "world 81\n",
      "very 1202\n",
      "little 359\n",
      "distress 19\n"
     ]
    }
   ],
   "source": [
    "#keys with array position\n",
    "bigasdist = alphaStopFreqDist(emmawords, stopwords)\n",
    "list(bigasdist.keys())[:99]\n",
    "for key in list(bigasdist.keys())[:30]:\n",
    "    print(key, bigasdist[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fca815",
   "metadata": {},
   "source": [
    "### Bigram Frequency Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3407d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigramDist(words, stoplist):\n",
    "    biDist = FreqDist()\n",
    "    uniDist = alphaStopFreqDist(words, stoplist)\n",
    "    for i in range(1, len(words)):\n",
    "        if words[i-1] in uniDist and words[i] in uniDist:\n",
    "            biword = words[i-1] + ' ' + words[i]\n",
    "            biDist[biword] +=1\n",
    "    return biDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a0a79da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['emma woodhouse', 'comfortable home', 'happy disposition', 'unite some', 'best blessings', 'lived nearly', 'nearly twenty', 'one years', 'world with', 'with very', 'very little', 'distress or', 'or vex', 'two daughters', 'most affectionate', 'indulgent father', 's marriage', 'house from', 'very early', 'early period', 'died too', 'too long', 'long ago', 'ago for'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bigarm Frequency Distribution\n",
    "shortbidist = bigramDist(shortwords, stopwords)\n",
    "shortbidist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f519294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma by 1\n",
      "by jane 2\n",
      "jane austen 1\n",
      "emma woodhouse 5\n",
      "comfortable home 2\n",
      "happy disposition 1\n",
      "unite some 1\n",
      "best blessings 2\n",
      "lived nearly 1\n",
      "nearly twenty 1\n",
      "one years 1\n",
      "world with 1\n",
      "with very 3\n",
      "very little 28\n",
      "distress or 1\n",
      "or vex 1\n",
      "two daughters 3\n",
      "most affectionate 1\n",
      "indulgent father 1\n",
      "s marriage 7\n",
      "house from 2\n",
      "very early 4\n",
      "early period 1\n",
      "died too 1\n",
      "too long 2\n",
      "long ago 4\n",
      "ago for 2\n",
      "more than 80\n",
      "than an 5\n",
      "an indistinct 1\n"
     ]
    }
   ],
   "source": [
    "emmabidist = bigramDist(emmawords, stopwords)\n",
    "for key in list(emmabidist.keys())[:30]:\n",
    "    print(key, emmabidist[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bfadba",
   "metadata": {},
   "source": [
    "### Exercise to be Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1767d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.book import text1\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5d24adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3\n",
      "moby 84\n",
      "dick 84\n",
      "by 1204\n",
      "herman 1\n",
      "melville 1\n",
      "1851 3\n",
      "] 1\n",
      "etymology 1\n",
      ". 6862\n",
      "( 210\n",
      "supplied 12\n",
      "a 4736\n",
      "late 30\n",
      "consumptive 1\n",
      "usher 2\n",
      "to 4625\n",
      "grammar 2\n",
      "school 10\n",
      ") 78\n",
      "the 14431\n",
      "pale 19\n",
      "-- 1070\n",
      "threadbare 1\n",
      "in 4172\n",
      "coat 28\n",
      ", 18713\n",
      "heart 91\n",
      "body 110\n",
      "and 6430\n"
     ]
    }
   ],
   "source": [
    "words1 = [w.lower() for w in text1]\n",
    "dist1=FreqDist(words1)\n",
    "\n",
    "for key in list(dist1.keys())[:30]:\n",
    "    print(key, dist1[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "876e08a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pattern recognition function\n",
    "def alphaFreqDist(words):\n",
    "    adist = FreqDist()\n",
    "    pattern = re.compile('.*[^a-z].*')\n",
    "    for word in words:\n",
    "        if not pattern.match(word):\n",
    "            adist.update([word])\n",
    "    return adist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f63ec863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moby 84\n",
      "dick 84\n",
      "by 1204\n",
      "herman 1\n",
      "melville 1\n",
      "etymology 1\n",
      "supplied 12\n",
      "a 4736\n",
      "late 30\n",
      "consumptive 1\n",
      "usher 2\n",
      "to 4625\n",
      "grammar 2\n",
      "school 10\n",
      "the 14431\n",
      "pale 19\n",
      "threadbare 1\n",
      "in 4172\n",
      "coat 28\n",
      "heart 91\n",
      "body 110\n",
      "and 6430\n",
      "brain 37\n",
      "i 2127\n",
      "see 272\n",
      "him 1067\n",
      "now 785\n",
      "he 1896\n",
      "was 1644\n",
      "ever 206\n"
     ]
    }
   ],
   "source": [
    "dist2 = alphaFreqDist(words1)\n",
    "dist2\n",
    "\n",
    "for key in list(dist2.keys())[:30]:\n",
    "    print(key, dist2[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a31c1922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moby 84\n",
      "dick 84\n",
      "by 1204\n",
      "herman 1\n",
      "melville 1\n",
      "etymology 1\n",
      "supplied 12\n",
      "late 30\n",
      "consumptive 1\n",
      "usher 2\n",
      "grammar 2\n",
      "school 10\n",
      "pale 19\n",
      "threadbare 1\n",
      "coat 28\n",
      "heart 91\n",
      "body 110\n",
      "brain 37\n",
      "see 272\n",
      "him 1067\n",
      "now 785\n",
      "ever 206\n",
      "dusting 2\n",
      "old 450\n",
      "lexicons 1\n",
      "grammars 2\n",
      "with 1722\n",
      "queer 44\n",
      "handkerchief 5\n",
      "mockingly 1\n"
     ]
    }
   ],
   "source": [
    "dist3 = alphaStopFreqDist(words1, stopwords)\n",
    "dist3\n",
    "\n",
    "for key in list(dist3.keys())[:30]:\n",
    "    print(key, dist3[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a5664c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moby dick 83\n",
      "dick by 1\n",
      "by herman 1\n",
      "herman melville 1\n",
      "supplied by 2\n",
      "late consumptive 1\n",
      "consumptive usher 1\n",
      "grammar school 1\n",
      "pale usher 1\n",
      "see him 19\n",
      "him now 8\n",
      "ever dusting 1\n",
      "old lexicons 1\n",
      "queer handkerchief 1\n",
      "mockingly embellished 1\n",
      "embellished with 2\n",
      "with all 46\n",
      "gay flags 1\n",
      "known nations 1\n",
      "old grammars 1\n",
      "somehow mildly 1\n",
      "mildly reminded 1\n",
      "reminded him 2\n",
      "while you 3\n",
      "you take 3\n",
      "school others 1\n",
      "teach them 1\n",
      "them by 6\n",
      "by what 10\n",
      "what name 1\n"
     ]
    }
   ],
   "source": [
    "dist4 = bigramDist(words1, stopwords)\n",
    "dist4\n",
    "\n",
    "for key in list(dist4.keys())[:30]:\n",
    "    print(key, dist4[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c080eda4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
