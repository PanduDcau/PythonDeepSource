{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"YGYtCwrsxTeM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e64081f5-deff-41a0-9dd8-15e30a5cc464","executionInfo":{"status":"ok","timestamp":1692509371759,"user_tz":-330,"elapsed":20859,"user":{"displayName":"Jack Kasippu","userId":"10749520589021927300"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Hq5rx4pHZs1D","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5a4140ad-e100-49aa-e3e6-7a2ead4be854","executionInfo":{"status":"ok","timestamp":1692509389645,"user_tz":-330,"elapsed":17281,"user":{"displayName":"Jack Kasippu","userId":"10749520589021927300"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting timm\n","  Downloading timm-0.9.5-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Collecting huggingface-hub (from timm)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors (from timm)\n","  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n","Installing collected packages: safetensors, huggingface-hub, timm\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 timm-0.9.5\n"]}],"source":["import cv2 # for preprocessing\n","\n","# For preprocessing and model creation\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from torchvision.datasets import CIFAR10\n","\n","# These libraries are used to load the dataset\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader\n","\n","# Python Image Library used for image preprocessing\n","from PIL import Image,ImageOps\n","\n","# is an optimization algorithm commonly used for training deep learning models\n","from torch.optim import Adam\n","\n","# (PyTorch Image Models) Used for creating the model\n","!pip install timm\n","from timm.models.vision_transformer import VisionTransformer"]},{"cell_type":"code","source":["# called to free up currently occupies GPU memory\n","torch.cuda.empty_cache()\n","\n","# is used to determine and set the CPU or GPU for tensor computations\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"w9VnzxQiZyc7","executionInfo":{"status":"ok","timestamp":1692509389646,"user_tz":-330,"elapsed":4,"user":{"displayName":"Jack Kasippu","userId":"10749520589021927300"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["############## Dataset Preparation\n","\n","transform_train = transforms.Compose([\n","    transforms.Resize((384, 384), antialias=True),  ## Resize input images\n","    transforms.RandomHorizontalFlip(), ## randomly rotates the training image horizontaly\n","    # transforms.Grayscale(),  # Convert images to grayscale\n","    transforms.ToTensor(), ## converts the image to a tensor\n","    # transforms.Normalize((0.406), (0.406))  # Normalize images\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ## This is where the normalizing is done\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize((384, 384), antialias=True),\n","    # transforms.Grayscale(),  # Convert images to grayscale\n","    transforms.ToTensor(),\n","    # transforms.Normalize((0.485), (0.485)),  # Normalize images\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","train_dataset = ImageFolder(root='/content/drive/MyDrive/BikeProject/Tyre Component/train', transform=transform_train)\n","test_dataset = ImageFolder(root='/content/drive/MyDrive/BikeProject/Tyre Component/test', transform=transform_test)\n","\n","## Data loaders are created here\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"],"metadata":{"id":"UsKE6FR5aki4","executionInfo":{"status":"ok","timestamp":1692509394966,"user_tz":-330,"elapsed":3058,"user":{"displayName":"Jack Kasippu","userId":"10749520589021927300"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Apply image filtering\n","\n","def apply_filter(image):\n","    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)  # Apply Gaussian smoothing\n","    return blurred_image\n","\n"],"metadata":{"id":"7CKOOYZfN7yF","executionInfo":{"status":"ok","timestamp":1692509398315,"user_tz":-330,"elapsed":591,"user":{"displayName":"Jack Kasippu","userId":"10749520589021927300"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Apply histogram equalization\n","\n","def apply_equalization(image):\n","    # Convert image to grayscale\n","    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    # Apply histogram equalization\n","    equalized_image = cv2.equalizeHist(gray_image)\n","    # Convert image back to BGR if needed\n","    equalized_image = cv2.cvtColor(equalized_image, cv2.COLOR_GRAY2BGR)\n","    return equalized_image\n","\n"],"metadata":{"id":"uZ_XD_84ReXr","executionInfo":{"status":"ok","timestamp":1692509399408,"user_tz":-330,"elapsed":2,"user":{"displayName":"Jack Kasippu","userId":"10749520589021927300"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Model Initialization\n","\n","num_classes = len(train_dataset.classes)\n","model = VisionTransformer(img_size=384, patch_size=16, in_chans=3, num_classes=num_classes)"],"metadata":{"id":"2YymSfE_aohn","executionInfo":{"status":"ok","timestamp":1692509405286,"user_tz":-330,"elapsed":4356,"user":{"displayName":"Jack Kasippu","userId":"10749520589021927300"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["############### Model Training\n","\n","model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","\n","# I have used Adam  (Adaptive Moment Estimation) optimizer here\n","optimizer = Adam(model.parameters(), lr=0.001)\n","\n","num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for images, labels in train_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(images)\n","        outputs = nn.functional.softmax(outputs, dim=1)  # Apply softmax activation to the model. Faster than Sigmoid\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"],"metadata":{"id":"sDO2F77pa1xP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8bb28c5e-9ec9-4fcb-ba24-ac2e3d328150","executionInfo":{"status":"ok","timestamp":1692510526470,"user_tz":-330,"elapsed":1121193,"user":{"displayName":"Jack Kasippu","userId":"10749520589021927300"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 1.2223\n","Epoch [2/10], Loss: 1.2146\n","Epoch [3/10], Loss: 1.2146\n","Epoch [4/10], Loss: 1.1917\n","Epoch [5/10], Loss: 1.2145\n","Epoch [6/10], Loss: 1.2057\n","Epoch [7/10], Loss: 1.1932\n","Epoch [8/10], Loss: 1.1932\n","Epoch [9/10], Loss: 1.2161\n","Epoch [10/10], Loss: 1.1932\n"]}]},{"cell_type":"code","source":["# Evaluation\n","model.eval()\n","correct = 0\n","total = 0\n","\n","predictions = []\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        outputs = nn.functional.softmax(outputs, dim=1)  # Apply softmax activation to the model'\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","        predictions.extend(predicted.cpu().numpy())\n","\n","accuracy = 100 * correct / total\n","print(num_classes) # print number of classes\n","print(f\"Accuracy on the test set: {accuracy:.2f}%\") ## printing accuracy\n"],"metadata":{"id":"XpgBNuZia6GG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"86e79fd4-d81a-4783-dda5-df07aa8e1cb2","executionInfo":{"status":"ok","timestamp":1692510543554,"user_tz":-330,"elapsed":17087,"user":{"displayName":"Jack Kasippu","userId":"10749520589021927300"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["3\n","Accuracy on the test set: 31.75%\n"]}]},{"cell_type":"code","source":["# Prediction Function\n","\n","def classify_image(image_path):\n","    image = Image.open(image_path)  # Load and convert image to grayscale\n","    image = transform_test(image).unsqueeze(0)\n","    image = image.to(device)\n","\n","    model.eval()\n","    with torch.no_grad():\n","        output = model(image)\n","        outputs = nn.functional.softmax(output, dim=1)  # Apply softmax activation to the model'\n","        _, predicted = torch.max(output, 1)\n","        return predicted.item()\n","\n","# Define the class label to name mapping\n","class_mapping = {\n","    0: \"good\",\n","    1: \"moderate\",\n","    2: \"bad\",\n","}"],"metadata":{"id":"X2M8XDV2oqum","executionInfo":{"status":"ok","timestamp":1692510543556,"user_tz":-330,"elapsed":3,"user":{"displayName":"Jack Kasippu","userId":"10749520589021927300"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Example usage\n","image_path = '/content/drive/MyDrive/BikeProject/Tyre Component/valid/bad/10.jpg'\n","predicted_class = classify_image(image_path)\n","print(f\"Predicted class: {predicted_class}\")\n","print(f\"Predicted class: {class_mapping.get(predicted_class)}\")"],"metadata":{"id":"02aZwbLQqvBM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b240813a-8d65-4234-e25b-87a0edb2ff0c","executionInfo":{"status":"ok","timestamp":1692510543943,"user_tz":-330,"elapsed":390,"user":{"displayName":"Jack Kasippu","userId":"10749520589021927300"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class: 0\n","Predicted class: good\n"]}]},{"cell_type":"code","source":["# Example usage\n","image_path = '/content/drive/MyDrive/BikeProject/Tyre Component/valid/good/20230517_151919.jpg'\n","predicted_class = classify_image(image_path)\n","print(f\"Predicted class: {predicted_class}\")\n","print(f\"Predicted class: {class_mapping.get(predicted_class)}\")"],"metadata":{"id":"Zw7V6dioq9Px","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692510544339,"user_tz":-330,"elapsed":397,"user":{"displayName":"Jack Kasippu","userId":"10749520589021927300"}},"outputId":"4e3f6b53-1b08-431c-ecec-469ca5a94df0"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class: 0\n","Predicted class: good\n"]}]},{"cell_type":"code","source":["# Example usage\n","image_path = '/content/drive/MyDrive/BikeProject/Tyre Component/valid/moderate/20230517_153737.jpg'\n","predicted_class = classify_image(image_path)\n","print(f\"Predicted class: {predicted_class}\")\n","print(f\"Predicted class: {class_mapping.get(predicted_class)}\")"],"metadata":{"id":"uzBAfPSBq9Je","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692510545200,"user_tz":-330,"elapsed":863,"user":{"displayName":"Jack Kasippu","userId":"10749520589021927300"}},"outputId":"30f1e2f9-7399-4f10-92a5-241f5f38267f"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class: 0\n","Predicted class: good\n"]}]},{"cell_type":"code","source":["# Save the trained model\n","# torch.save(model.state_dict(), \"vision_transformer_model.pth\")"],"metadata":{"id":"6iCGuuGuYjHO"},"execution_count":null,"outputs":[]}]}